{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGG Data Fetcher\n",
    "\n",
    "This script will fetch items data from BoardGameGeek API and store the data in a CSV file. I updated the [preivous script](https://www.drangovski.com/article/boardgamegeek-board-games-data-fetching). Since the API response is in XML format and since there is no endpoint to fetch all items at once, the previous script would loop through a provided IDs range, making calls one by one for each item. That's not optimal, it takes long time for larger range of IDs (currently the highest number of items (IDs) available on BGG goes as high as 400k+) and the results may not be reliable. Therefore, with some modifications in this script, more item IDs will be added as parameter value to a single request url, and with that, a single response will return multiple items (~800 was the highest number that a single response returned back. BGG may eventually change this later; you can easily tweak `batch_size` in order to adjust if needed).\n",
    "\n",
    "The information fetched and stored for each board game is the following:\n",
    "\n",
    "`name`, `game_id`, `type`, `rating`, `weight`, `year_published`, `min_players`, `max_players`, `min_play_time`, `max_pay_time`, `min_age`, `owned_by`, `categories`, `mechanics`, `designers`, `artists` and `publishers`.\n",
    "\n",
    "We start by importing the needed libraries for this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import DictWriter\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a function that will be called when the script is completed based on the range of IDs. Also, if there is an error when making a request, this function will be called in order to store all the data appended to the `games` list up to the point when the exeption happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file saving function\n",
    "def save_to_csv(games):\n",
    "    csv_header = [\n",
    "        'name', 'game_id', 'type', 'rating', 'weight', 'year_published', 'min_players', 'max_players',\n",
    "        'min_play_time', 'max_play_time', 'min_age', 'owned_by', 'categories',\n",
    "        'mechanics', 'designers', 'artists', 'publishers'\n",
    "    ]\n",
    "    with open('bgg.csv', 'a', encoding='UTF8') as f:\n",
    "        dictwriter_object = DictWriter(f, fieldnames=csv_header)\n",
    "        if f.tell() == 0:\n",
    "            dictwriter_object.writeheader()\n",
    "        dictwriter_object.writerows(games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to define the headers for the requests. Pause between requests can be set through `SLEEP_BETWEEN_REQUESTS` (I have seen some information that rate limit is 2 requests per second, but it may be outdated information since I had no trouble with pause being set to 0). Additionally, here are set the values for starting point ID (`start_id_range`), maximum range (`max_id_range`) and `batch_size` is how many games should the response return back. Base url is defined in this section, but the IDs are added in the next part of the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request url headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:85.0) Gecko/20100101 Firefox/85.0\",\n",
    "    \"Accept-Language\": \"en-GB, en-US, q=0.9, en\"\n",
    "}\n",
    "\n",
    "# Define sleep timer value between requests\n",
    "SLEEP_BETWEEN_REQUEST = 0\n",
    "\n",
    "# Define max id range\n",
    "start_id_range = 0\n",
    "max_id_range = 403000\n",
    "batch_size = 800\n",
    "base_url = \"https://boardgamegeek.com/xmlapi2/thing?id=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The in the following part is the main logic of this script. At first, based on the batch size, it will make a string of IDs that are within the defined IDs range, but not more IDs than the defined number in `batch_size` and that will be appended to `id` parameter of the url. With that, each response will return data for the number of items that is same as the batch size. After that it will process and append the data to the `games` list for each response and finally append to the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop that will iterate between the starting and maximum range in intervals of the batch size\n",
    "for batch_start in range(start_id_range, max_id_range, batch_size):\n",
    "    # Make sure that the batch size will not exceed the maximum ids range\n",
    "    batch_end = min(batch_start + batch_size - 1, max_id_range)\n",
    "    # Join and append to the url the IDs within batch size\n",
    "    ids = \",\".join(map(str, range(batch_start, batch_end + 1)))\n",
    "    url = f\"{base_url}?id={ids}&stats=1\"\n",
    "    \n",
    "    # If by any chance there is an error, this will throw the exception and continue on the next batch\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, features=\"html.parser\")\n",
    "        items = soup.find_all(\"item\")\n",
    "        games = []\n",
    "        for item in items:\n",
    "            if item:\n",
    "                try:\n",
    "                    # Find values in the XML\n",
    "                    name = item.find(\"name\")['value'] if item.find(\"name\") is not None else 0\n",
    "                    year_published = item.find(\"yearpublished\")['value'] if item.find(\"yearpublished\") is not None else 0\n",
    "                    min_players = item.find(\"minplayers\")['value'] if item.find(\"minplayers\") is not None else 0\n",
    "                    max_players = item.find(\"maxplayers\")['value'] if item.find(\"maxplayers\") is not None else 0\n",
    "                    min_play_time = item.find(\"minplaytime\")['value'] if item.find(\"minplaytime\") is not None else 0\n",
    "                    max_play_time = item.find(\"maxplaytime\")['value'] if item.find(\"maxplaytime\") is not None else 0\n",
    "                    min_age = item.find(\"minage\")['value'] if item.find(\"minage\") is not None else 0\n",
    "                    rating = item.find(\"average\")['value'] if item.find(\"average\") is not None else 0\n",
    "                    weight = item.find(\"averageweight\")['value'] if item.find(\"averageweight\") is not None else 0\n",
    "                    owned = item.find(\"owned\")['value'] if item.find(\"owned\") is not None else 0\n",
    "                    \n",
    "                    \n",
    "                    link_type = {'categories': [], 'mechanics': [], 'designers': [], 'artists': [], 'publishers': []}\n",
    "                    \n",
    "                    links = item.find_all(\"link\")\n",
    "            \n",
    "                    # Append value(s) for each link type\n",
    "                    for link in links:                            \n",
    "                        if link['type'] == \"boardgamecategory\":\n",
    "                            link_type['categories'].append(link['value'])\n",
    "                        if link['type'] == \"boardgamemechanic\":\n",
    "                            link_type['mechanics'].append(link['value'])\n",
    "                        if link['type'] == \"boardgamedesigner\":\n",
    "                            link_type['designers'].append(link['value'])\n",
    "                        if link['type'] == \"boardgameartist\":\n",
    "                            link_type['artists'].append(link['value'])\n",
    "                        if link['type'] == \"boardgamepublisher\":\n",
    "                            link_type['publishers'].append(link['value'])\n",
    "                    \n",
    "                    # Append 0 if there is no value for any link type\n",
    "                    for key, ltype in link_type.items():\n",
    "                        if not ltype:\n",
    "                            ltype.append(\"0\")\n",
    "                         \n",
    "                    game = {\n",
    "                        \"name\": name,\n",
    "                        \"game_id\": item['id'],\n",
    "                        \"type\": item['type'],\n",
    "                        \"rating\": rating,\n",
    "                        \"weight\": weight,\n",
    "                        \"year_published\": year_published,\n",
    "                        \"min_players\": min_players,\n",
    "                        \"max_players\": max_players,\n",
    "                        \"min_play_time\": min_play_time,\n",
    "                        \"max_play_time\": max_play_time,\n",
    "                        \"min_age\": min_age,\n",
    "                        \"owned_by\": owned,\n",
    "                        \"categories\": ', '.join(link_type['categories']),\n",
    "                        \"mechanics\": ', '.join(link_type['mechanics']),\n",
    "                        \"designers\": ', '.join(link_type['designers']),\n",
    "                        \"artists\": ', '.join(link_type['artists']),\n",
    "                        \"publishers\": ', '.join(link_type['publishers']),\n",
    "                    }\n",
    "                    \n",
    "                    # Append current item to games list\n",
    "                    games.append(game)\n",
    "                except TypeError:\n",
    "                    print(\">>> NoneType error. Continued on the next item.\")\n",
    "                    continue\n",
    "        save_to_csv(games)\n",
    "               \n",
    "        print(f\">>> Request successful for batch {batch_start}-{batch_end}\")\n",
    "    else:\n",
    "        print(f\">>> FAILED batch {batch_start}-{batch_end}\")\n",
    "    \n",
    "    # Pause between requests\n",
    "    time.sleep(SLEEP_BETWEEN_REQUEST)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can preview the first few rows of records in the CSV file as pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the CSV as pandas DataFrame\n",
    "df = pd.read_csv('./bgg.csv')\n",
    "print(df.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
